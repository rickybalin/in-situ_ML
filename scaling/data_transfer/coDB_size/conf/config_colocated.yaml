# Database config
database:
    # redis, keydb
    backend: "BACKEND_REPLACE"
    # colocated, clustered
    launch: "colocated"
    port: 6780
    # Polaris: lo, hsn0, uds
    # Cannot use lo for clustered
    network_interface: "uds"

# Run config
run_args:
    # any value
    nodes: 1
    # any value for clustered, 1 for colocated
    db_nodes: 1
    # any value for clustered, 1 for colocated
    sim_nodes: 1
    # machine specific, 32 for Polaris 48 for ThetaGPU
    cores_pn: 32
    # any number
    simprocs: 24
    # any number up to limits of CPU
    simprocs_pn: 24
    # any number
    mlprocs: 1
    # any number up to limits of CPU/GPU
    mlprocs_pn: 1
    # any number up to limits of CPU
    dbprocs_pn: DBPROCS_REPLACE
    # Polaris: none, core, list, numa
    sim_cpu_bind: "socket"
    # Polaris: none, core, list, numa
    ml_cpu_bind: "none"

# Experiment config
experiment:
    name: "client-scaling"
    # pbs, cobalt
    launcher: "pbs"

# Model Inference config
model:
    path: ""
    backend: ""
    # cpu, gpu
    device: ""
    # 0 - simprocs for clustered
    # 0 - simprocs_pn for colocated
    batch: 0
    # 1 - number of GPUs available for inference
    # 1 if device=cpu
    devices_per_node: 1
    # fp32, fp64
    precision: "fp32"
    # data size
    size: [32, 32, 32]

# Simulation config
sim:
    executable: "/grand/datascience/balin/SC23/SmartSim/scaling/data_transfer/single_node/coDB_size/safe/src/clientFtn.exe"
    # Device for simulation: cuda, cpu
    device: "cpu"

# Distributed training config
train:
    executable: ""
    # Device for simulation: cuda, cpu
    device: ""

# Logging config
# no, fom, verbose, verbose-perf. Set to fom for optimization
logging: "verbose-perf" 
